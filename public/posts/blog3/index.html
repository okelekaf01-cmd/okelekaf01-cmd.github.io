<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思 | wwxdsg的个人博客</title><meta name=keywords content="数据可视化,LLM应用,架构设计"><meta name=description content="探讨智能图表推荐系统中的追问机制设计，以及在真实脏数据场景下的实战反思"><meta name=author content="wwxdsg"><link rel=canonical href=https://okelekaf01-cmd.github.io/posts/blog3/><link crossorigin=anonymous href=/assets/css/stylesheet.a29c24210eb31d9ce56f669c66a35c9c51b17376b7764e336a49af7dec914cf0.css integrity="sha256-opwkIQ6zHZzlb2acZqNcnFGxc3a3dk4zakmvfeyRTPA=" rel="preload stylesheet" as=style><link rel=icon href=https://okelekaf01-cmd.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://okelekaf01-cmd.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://okelekaf01-cmd.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://okelekaf01-cmd.github.io/apple-touch-icon.png><link rel=mask-icon href=https://okelekaf01-cmd.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://okelekaf01-cmd.github.io/posts/blog3/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://okelekaf01-cmd.github.io/posts/blog3/"><meta property="og:site_name" content="wwxdsg的个人博客"><meta property="og:title" content="从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思"><meta property="og:description" content="探讨智能图表推荐系统中的追问机制设计，以及在真实脏数据场景下的实战反思"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-07T16:00:00+08:00"><meta property="article:modified_time" content="2026-02-07T16:00:00+08:00"><meta property="article:tag" content="数据可视化"><meta property="article:tag" content="LLM应用"><meta property="article:tag" content="架构设计"><meta name=twitter:card content="summary"><meta name=twitter:title content="从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思"><meta name=twitter:description content="探讨智能图表推荐系统中的追问机制设计，以及在真实脏数据场景下的实战反思"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://okelekaf01-cmd.github.io/posts/"},{"@type":"ListItem","position":2,"name":"从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思","item":"https://okelekaf01-cmd.github.io/posts/blog3/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思","name":"从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思","description":"探讨智能图表推荐系统中的追问机制设计，以及在真实脏数据场景下的实战反思","keywords":["数据可视化","LLM应用","架构设计"],"articleBody":"我在刚开始写这个项目的时候觉得\"我都用 AI 了为什么还要写这么多逻辑\"，不是简单的给ai套个壳子就能有不错的效果了吗，后来发现事情没有我想的那么简单\n这本质上是调用功能和构建产品的区别 调用功能：\n# 调一下 df.chat()，它只能算个 Demo result = df.chat(\"帮我分析这个数据\") 构建产品：\n处理脏数据 提供图表推荐 设计追问机制 管理 Session 这些才是让 OpsMind 能在真实办公场景下不\"翻车\"的核心竞争力。\n大模型应用的本质 大模型应用不是简单的\"调 API\"，而是构建一个完整的产品系统。LLM 只是其中一个组件，真正的价值在于如何将其与业务逻辑、数据处理、用户体验有机结合。\n1. 缘起：图表推荐，只给类型是不够的 最近在折腾智能图表推荐系统。做过数据可视化的同学都知道，系统告诉你\"这组数据适合散点图\"只完成了 30% 的工作。剩下的 70% 痛点在于：\n到底哪一列该放 X 轴？ 哪一列是 Y 轴？ 是否需要图例（Legend）分组？ 为了解决这个映射问题，我闭关写了一套混合模式的追问机制。当时我觉得方案已经非常闭环了：能推断的直接出图，不确定的再来问用户。\n2. 方案设计：既要智能，又要掌控感 我设计的核心是混合模式（Hybrid Mode）。\n快速通道 利用 LLM 强大的语义理解能力，直接分析用户的 Query 和数据特征（Data Features），给出置信度高的列映射。\n透明展示 系统不搞\"黑盒\"，推断结果会清晰地展示给用户。\n追问流程 如果 LLM 只有 50% 的把握，或者发现数据中存在多个可能的数值列，系统会触发 ClarificationQuestion。\n为了支撑这个机制，我重构了底层数据结构，定义了 ChartColumnMapping（列映射）和 ChartInference（推断结果）等数据类，并为 15 种常用图表配置了严格的属性要求（CHART_REQUIREMENTS）。\n# 核心数据类：让推断结果结构化 @dataclass class ChartInference: chart_type: str # 图表类型 column_mapping: ChartColumnMapping # 具体的列映射方案 confidence: float # 置信度 (0-1) needs_clarification: bool = False # 是否需要反向追问用户 3. 翻车现场：当\"脏数据\"遇到\"理想逻辑\" 代码写完，本地测试集跑了一遍，全绿通过。我志得意满，觉得这套 450 行代码的逻辑已经无懈可击了。\n正好有个朋友在做业务分析，我拉他来当首位\"受害者\"。结果他顺手甩给我一张真实业务场景的表格——我当场就傻眼了。\n真实场景的不实用 那是一张完全没有经过清洗的数据：\n表头命名随心所欲：有的叫 col_1，有的叫 tmp_data_v2。\n数据类型混乱：本该是数值的列里混着\"暂无\"、“N/A\"甚至是注释。\n冗余信息爆炸：一张表几十列，LLM 在分析语义时被大量的无关干扰项带跑了。\n理想逻辑的溃败 我预设的\"根据列名和特征自动推断\"在这些脏数据面前溃不成军。LLM 给出的映射结果置信度极低，甚至直接把日期列映射到了 Y 轴。\n而我设计的追问机制，因为原始数据太乱，生成的选项（Options）里塞满了垃圾信息，用户看着几十个乱七八糟的列名，根本选不出来。\n那一刻我意识到：做的项目要贴合真实场景从用户角度出发，光是跑自己的东西那只能叫工具\n4. 核心实现回顾（虽然翻车，但逻辑依然是骨干） 虽然在脏数据上吃到了教训，但这套追问机制的骨架依然是必要的。我主要实现了以下几个核心方法：\ninfer_column_mapping()：这是大脑 负责调用 LLM 把用户那句\"看看去年的销售趋势\"翻译成 x_axis='date', y_axis='sales'。\ncheck_clarification_needed()：这是守门员 当置信度低于 0.7，或者候选列太多时，它会强行切断自动流程，进入追问模式。\ngenerate_clarification_questions()：这是外交官 它会根据图表需求（比如柱状图需要一个分类轴和一个数值轴）生成交互问题。\n# 追问流程的示例 if results[0][\"inference\"][\"needs_clarification\"]: # 自动生成针对性的问题，比如\"哪一列代表你想分析的分类？\" clarification = recommender.generate_clarification_questions(\"bar\", df, inference) # 展示给用户进行手动修正 5. 痛定思痛：下一步计划 这次\"翻车\"让我清醒了。对于非专业用户来说，他们可能连自己的数据里有哪些异常值都不知道，指望他们能通过简单的追问完成复杂的映射是不现实的。\n下一步改进计划 我打算在推荐器之前增加一个\"预处理与诊断层”：\n自动检测脏数据：在推断前先给数据\"把脉\"，识别格式错误和缺失值。\n智能列清洗建议：不仅仅是问用户选哪一列，还要提示用户\"这一列有非数值字符，是否需要我帮你剔除？\"\n语义降噪：先利用 LLM 对所有列名进行一次语义降维，过滤掉无关的冗余列。\n总结 好的工具不应该只是\"聪明\"地处理正确的信息，更要\"强壮\"地面对混乱的现实。\n开发任务还在继续，预处理功能，安排！\n最后的思考 从\"调包侠\"到\"架构师\"的转变，本质上是从\"使用工具\"到\"创造价值\"的进化。\n调包侠关注的是：这个 API 能做什么？ 架构师思考的是：这个产品如何解决真实问题？ 大模型应用开发不是简单的 API 调用，而是需要你理解业务场景、设计合理架构、处理边界情况、提供良好体验的完整工程实践。\n这才是真正的 AI 应用开发。\n","wordCount":"162","inLanguage":"en","datePublished":"2026-02-07T16:00:00+08:00","dateModified":"2026-02-07T16:00:00+08:00","author":{"@type":"Person","name":"wwxdsg"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://okelekaf01-cmd.github.io/posts/blog3/"},"publisher":{"@type":"Organization","name":"wwxdsg的个人博客","logo":{"@type":"ImageObject","url":"https://okelekaf01-cmd.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://okelekaf01-cmd.github.io/ accesskey=h title="wwxdsg的个人博客 (Alt + H)">wwxdsg的个人博客</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://okelekaf01-cmd.github.io/ title=主页><span>主页</span></a></li><li><a href=https://okelekaf01-cmd.github.io/projects/ title=个人项目><span>个人项目</span></a></li><li><a href=https://okelekaf01-cmd.github.io/posts/ title=博客><span>博客</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">从脑补到实战：我的智能图表推荐器追问机制实现与翻车反思</h1><div class=post-description>探讨智能图表推荐系统中的追问机制设计，以及在真实脏数据场景下的实战反思</div><div class=post-meta><span title='2026-02-07 16:00:00 +0800 CST'>February 7, 2026</span>&nbsp;·&nbsp;<span>wwxdsg</span></div></header><div class=post-content><p>我在刚开始写这个项目的时候觉得"我都用 AI 了为什么还要写这么多逻辑"，不是简单的给ai套个壳子就能有不错的效果了吗，后来发现事情没有我想的那么简单</p><h3 id=这本质上是调用功能和构建产品的区别>这本质上是调用功能和构建产品的区别<a hidden class=anchor aria-hidden=true href=#这本质上是调用功能和构建产品的区别>#</a></h3><p><strong>调用功能</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 调一下 df.chat()，它只能算个 Demo</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>chat(<span style=color:#e6db74>&#34;帮我分析这个数据&#34;</span>)
</span></span></code></pre></div><p><strong>构建产品</strong>：</p><ul><li>处理脏数据</li><li>提供图表推荐</li><li>设计追问机制</li><li>管理 Session</li></ul><p>这些才是让 OpsMind 能在真实办公场景下不"翻车"的核心竞争力。</p><h3 id=大模型应用的本质>大模型应用的本质<a hidden class=anchor aria-hidden=true href=#大模型应用的本质>#</a></h3><p>大模型应用不是简单的"调 API"，而是构建一个完整的产品系统。LLM 只是其中一个组件，真正的价值在于如何将其与业务逻辑、数据处理、用户体验有机结合。</p><hr><h2 id=1-缘起图表推荐只给类型是不够的>1. 缘起：图表推荐，只给类型是不够的<a hidden class=anchor aria-hidden=true href=#1-缘起图表推荐只给类型是不够的>#</a></h2><p>最近在折腾智能图表推荐系统。做过数据可视化的同学都知道，系统告诉你"这组数据适合散点图"只完成了 30% 的工作。剩下的 70% 痛点在于：</p><ul><li>到底哪一列该放 X 轴？</li><li>哪一列是 Y 轴？</li><li>是否需要图例（Legend）分组？</li></ul><p>为了解决这个映射问题，我闭关写了一套<strong>混合模式的追问机制</strong>。当时我觉得方案已经非常闭环了：能推断的直接出图，不确定的再来问用户。</p><hr><h2 id=2-方案设计既要智能又要掌控感>2. 方案设计：既要智能，又要掌控感<a hidden class=anchor aria-hidden=true href=#2-方案设计既要智能又要掌控感>#</a></h2><p>我设计的核心是<strong>混合模式（Hybrid Mode）</strong>。</p><h3 id=快速通道>快速通道<a hidden class=anchor aria-hidden=true href=#快速通道>#</a></h3><p>利用 LLM 强大的语义理解能力，直接分析用户的 Query 和数据特征（Data Features），给出置信度高的列映射。</p><h3 id=透明展示>透明展示<a hidden class=anchor aria-hidden=true href=#透明展示>#</a></h3><p>系统不搞"黑盒"，推断结果会清晰地展示给用户。</p><h3 id=追问流程>追问流程<a hidden class=anchor aria-hidden=true href=#追问流程>#</a></h3><p>如果 LLM 只有 50% 的把握，或者发现数据中存在多个可能的数值列，系统会触发 <code>ClarificationQuestion</code>。</p><p>为了支撑这个机制，我重构了底层数据结构，定义了 <code>ChartColumnMapping</code>（列映射）和 <code>ChartInference</code>（推断结果）等数据类，并为 15 种常用图表配置了严格的属性要求（<code>CHART_REQUIREMENTS</code>）。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 核心数据类：让推断结果结构化</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@dataclass</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ChartInference</span>:
</span></span><span style=display:flex><span>    chart_type: str                   <span style=color:#75715e># 图表类型</span>
</span></span><span style=display:flex><span>    column_mapping: ChartColumnMapping <span style=color:#75715e># 具体的列映射方案</span>
</span></span><span style=display:flex><span>    confidence: float                 <span style=color:#75715e># 置信度 (0-1)</span>
</span></span><span style=display:flex><span>    needs_clarification: bool <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span> <span style=color:#75715e># 是否需要反向追问用户</span>
</span></span></code></pre></div><hr><h2 id=3-翻车现场当脏数据遇到理想逻辑>3. 翻车现场：当"脏数据"遇到"理想逻辑"<a hidden class=anchor aria-hidden=true href=#3-翻车现场当脏数据遇到理想逻辑>#</a></h2><p>代码写完，本地测试集跑了一遍，全绿通过。我志得意满，觉得这套 450 行代码的逻辑已经无懈可击了。</p><p>正好有个朋友在做业务分析，我拉他来当首位"受害者"。结果他顺手甩给我一张真实业务场景的表格——我当场就傻眼了。</p><h3 id=真实场景的不实用>真实场景的不实用<a hidden class=anchor aria-hidden=true href=#真实场景的不实用>#</a></h3><p>那是一张完全没有经过清洗的数据：</p><p><strong>表头命名随心所欲</strong>：有的叫 <code>col_1</code>，有的叫 <code>tmp_data_v2</code>。</p><p><strong>数据类型混乱</strong>：本该是数值的列里混着"暂无"、&ldquo;N/A"甚至是注释。</p><p><strong>冗余信息爆炸</strong>：一张表几十列，LLM 在分析语义时被大量的无关干扰项带跑了。</p><h3 id=理想逻辑的溃败>理想逻辑的溃败<a hidden class=anchor aria-hidden=true href=#理想逻辑的溃败>#</a></h3><p>我预设的"根据列名和特征自动推断"在这些脏数据面前溃不成军。LLM 给出的映射结果置信度极低，甚至直接把日期列映射到了 Y 轴。</p><p>而我设计的追问机制，因为原始数据太乱，生成的选项（Options）里塞满了垃圾信息，用户看着几十个乱七八糟的列名，根本选不出来。</p><p>那一刻我意识到：做的项目要贴合真实场景从用户角度出发，光是跑自己的东西那只能叫工具</p><hr><h2 id=4-核心实现回顾虽然翻车但逻辑依然是骨干>4. 核心实现回顾（虽然翻车，但逻辑依然是骨干）<a hidden class=anchor aria-hidden=true href=#4-核心实现回顾虽然翻车但逻辑依然是骨干>#</a></h2><p>虽然在脏数据上吃到了教训，但这套追问机制的骨架依然是必要的。我主要实现了以下几个核心方法：</p><h3 id=infer_column_mapping这是大脑><code>infer_column_mapping()</code>：这是大脑<a hidden class=anchor aria-hidden=true href=#infer_column_mapping这是大脑>#</a></h3><p>负责调用 LLM 把用户那句"看看去年的销售趋势"翻译成 <code>x_axis='date', y_axis='sales'</code>。</p><h3 id=check_clarification_needed这是守门员><code>check_clarification_needed()</code>：这是守门员<a hidden class=anchor aria-hidden=true href=#check_clarification_needed这是守门员>#</a></h3><p>当置信度低于 0.7，或者候选列太多时，它会强行切断自动流程，进入追问模式。</p><h3 id=generate_clarification_questions这是外交官><code>generate_clarification_questions()</code>：这是外交官<a hidden class=anchor aria-hidden=true href=#generate_clarification_questions这是外交官>#</a></h3><p>它会根据图表需求（比如柱状图需要一个分类轴和一个数值轴）生成交互问题。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 追问流程的示例</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> results[<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#34;inference&#34;</span>][<span style=color:#e6db74>&#34;needs_clarification&#34;</span>]:
</span></span><span style=display:flex><span>    <span style=color:#75715e># 自动生成针对性的问题，比如&#34;哪一列代表你想分析的分类？&#34;</span>
</span></span><span style=display:flex><span>    clarification <span style=color:#f92672>=</span> recommender<span style=color:#f92672>.</span>generate_clarification_questions(<span style=color:#e6db74>&#34;bar&#34;</span>, df, inference)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 展示给用户进行手动修正</span>
</span></span></code></pre></div><hr><h2 id=5-痛定思痛下一步计划>5. 痛定思痛：下一步计划<a hidden class=anchor aria-hidden=true href=#5-痛定思痛下一步计划>#</a></h2><p>这次"翻车"让我清醒了。对于非专业用户来说，他们可能连自己的数据里有哪些异常值都不知道，指望他们能通过简单的追问完成复杂的映射是不现实的。</p><h3 id=下一步改进计划>下一步改进计划<a hidden class=anchor aria-hidden=true href=#下一步改进计划>#</a></h3><p>我打算在推荐器之前增加一个"预处理与诊断层&rdquo;：</p><ol><li><p><strong>自动检测脏数据</strong>：在推断前先给数据"把脉"，识别格式错误和缺失值。</p></li><li><p><strong>智能列清洗建议</strong>：不仅仅是问用户选哪一列，还要提示用户"这一列有非数值字符，是否需要我帮你剔除？"</p></li><li><p><strong>语义降噪</strong>：先利用 LLM 对所有列名进行一次语义降维，过滤掉无关的冗余列。</p></li></ol><h3 id=总结>总结<a hidden class=anchor aria-hidden=true href=#总结>#</a></h3><p><strong>好的工具不应该只是"聪明"地处理正确的信息，更要"强壮"地面对混乱的现实。</strong></p><p>开发任务还在继续，预处理功能，安排！</p><hr><h2 id=最后的思考>最后的思考<a hidden class=anchor aria-hidden=true href=#最后的思考>#</a></h2><p>从"调包侠"到"架构师"的转变，本质上是从"使用工具"到"创造价值"的进化。</p><ul><li><strong>调包侠</strong>关注的是：这个 API 能做什么？</li><li><strong>架构师</strong>思考的是：这个产品如何解决真实问题？</li></ul><p>大模型应用开发不是简单的 API 调用，而是需要你理解业务场景、设计合理架构、处理边界情况、提供良好体验的完整工程实践。</p><p>这才是真正的 AI 应用开发。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://okelekaf01-cmd.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/>数据可视化</a></li><li><a href=https://okelekaf01-cmd.github.io/tags/llm%E5%BA%94%E7%94%A8/>LLM应用</a></li><li><a href=https://okelekaf01-cmd.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>架构设计</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://okelekaf01-cmd.github.io/>wwxdsg的个人博客</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>